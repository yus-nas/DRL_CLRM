2021-09-30 20:43:26,766	ERROR services.py:1281 -- Failed to start the dashboard: Failed to read dashbord log: [Errno 2] No such file or directory: '/tmp/ray/session_2021-09-30_20-43-01_093762_28735/logs/dashboard.log'
2021-09-30 20:53:24,550	INFO worker.py:726 -- Connecting to existing Ray cluster at address: 10.19.5.33:8479
2021-09-30 20:53:27,143	WARNING trial_runner.py:229 -- The maximum number of pending trials has been automatically set to the number of available cluster CPUs, which is high (154 CPUs/pending trials). If you're running an experiment with a large number of trials, this could lead to scheduling overhead. In this case, consider setting the `TUNE_MAX_PENDING_TRIALS_PG` environment variable to the desired maximum number of concurrent trials.
2021-09-30 20:54:12,151	WARNING worker.py:1114 -- The actor or task with ID ffffffffffffffffaa28ba393ec921dcb25b8a6c01000000 cannot be scheduled right now. It requires {CPU_group_e706ad6201b460d63c372b84289a97fd: 1.000000} for placement, but this node only has remaining {0.000000/20.000000 CPU, 173.542469 GiB/173.542469 GiB memory, 74.375344 GiB/74.375344 GiB object_store_memory, 1.000000/1.000000 CPU_group_17_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_16_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_33_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_20_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_30_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_18_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_31_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_32_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_25_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_21_e706ad6201b460d63c372b84289a97fd, 20.000000/20.000000 CPU_group_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_35_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_19_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 node:10.19.5.56, 1.000000/1.000000 CPU_group_27_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_29_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_23_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_24_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_34_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_28_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_22_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_26_e706ad6201b460d63c372b84289a97fd}
. In total there are 0 pending tasks and 20 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale or if you specified a runtime_env for this task or actor because it takes time to install.
2021-09-30 20:54:12,161	WARNING worker.py:1114 -- The actor or task with ID ffffffffffffffff84fba518c94c5c3ae87cb9d201000000 cannot be scheduled right now. It requires {CPU_group_e706ad6201b460d63c372b84289a97fd: 1.000000} for placement, but this node only has remaining {0.000000/20.000000 CPU, 172.354871 GiB/172.354871 GiB memory, 73.866373 GiB/73.866373 GiB object_store_memory, 1.000000/1.000000 CPU_group_114_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_104_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_107_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_101_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_109_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_115_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_103_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_108_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_110_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_98_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_113_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_111_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_102_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_105_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 node:10.19.5.54, 20.000000/20.000000 CPU_group_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_100_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_106_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_96_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_97_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_99_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_112_e706ad6201b460d63c372b84289a97fd}
. In total there are 0 pending tasks and 20 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale or if you specified a runtime_env for this task or actor because it takes time to install.
2021-09-30 20:54:13,200	WARNING worker.py:1114 -- The actor or task with ID ffffffffffffffff10785b2147d37864b5bf9ea001000000 cannot be scheduled right now. It requires {CPU_group_e706ad6201b460d63c372b84289a97fd: 1.000000} for placement, but this node only has remaining {0.000000/20.000000 CPU, 171.314770 GiB/171.314770 GiB memory, 73.420616 GiB/73.420616 GiB object_store_memory, 1.000000/1.000000 CPU_group_40_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_43_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_55_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_54_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_46_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_47_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_49_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_38_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_41_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_37_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_52_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 node:10.19.5.62, 1.000000/1.000000 CPU_group_51_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_39_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_44_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_36_e706ad6201b460d63c372b84289a97fd, 20.000000/20.000000 CPU_group_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_45_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_48_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_50_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_42_e706ad6201b460d63c372b84289a97fd, 1.000000/1.000000 CPU_group_53_e706ad6201b460d63c372b84289a97fd}
. In total there are 0 pending tasks and 20 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale or if you specified a runtime_env for this task or actor because it takes time to install.
2021-10-02 23:11:16,487	INFO tune.py:549 -- Total run time: 181071.62 seconds (181068.81 seconds for the tuning loop).
